---
title: 传输层
---
# 四、传输层

## 1、UDP

UDP（用户数据报协议）是传输层的协议，功能即为在IP的数据报服务之上增加了最基本的服务：复用和分用以及差错检测。

UDP提供不可靠服务，具有TCP所没有的优势：

1、UDP无连接，时间上不存在建立连接需要的时延。空间上，TCP需要在端系统中维护连接状态，需要一定的开销。此连接装入包括接收和发送缓存，拥塞控制参数和序号与确认号的参数。UDP不维护连接状态，也不跟踪这些参数，开销小。空间和时间上都具有优势。

举个例子：
1. DNS如果运行在TCP之上而不是UDP，那么DNS的速度将会慢很多。
2. HTTP使用TCP而不是UDP，是因为对于基于文本数据的Web网页来说，可靠性很重要。
3. 同一种专用应用服务器在支持UDP时，一定能支持更多的活动客户机。

2、分组首部开销小，TCP首部20字节，UDP首部8字节。

3、UDP没有拥塞控制，应用层能够更好的控制要发送的数据和发送时间，网络中的拥塞控制也不会影响主机的发送速率。某些实时应用要求以稳定的速度发送，能容忍一些数据的丢失，但是不能允许有较大的时延（比如实时视频，直播等）

4、UDP提供尽最大努力的交付，不保证可靠交付。所有维护传输可靠性的工作需要用户在应用层来完成。没有TCP的确认机制、重传机制。如果因为网络原因没有传送到对端，UDP也不会给应用层返回错误信息

5、UDP是面向报文的，对应用层交下来的报文，添加首部后直接向下交付为IP层，既不合并，也不拆分，保留这些报文的边界。对IP层交上来UDP用户数据报，在去除首部后就原封不动地交付给上层应用进程，报文不可分割，是UDP数据报处理的最小单位。
正是因为这样，UDP显得不够灵活，不能控制读写数据的次数和数量。比如我们要发送100个字节的报文，我们调用一次sendto函数就会发送100字节，对端也需要用recvfrom函数一次性接收100字节，不能使用循环每次获取10个字节，获取十次这样的做法。

6、UDP常用一次性传输比较少量数据的网络应用，如DNS,SNMP等，因为对于这些应用，若是采用TCP，为连接的创建，维护和拆除带来不小的开销。UDP也常用于多媒体应用（如IP电话，实时视频会议，流媒体等）数据的可靠传输对他们而言并不重要，TCP的拥塞控制会使他们有较大的延迟，也是不可容忍的。

7、UDP支持一对一、一对多、多对一和多对多的交互通信。

### 1.1UDP首部格式
![](https://raw.githubusercontent.com/Hewie8023/VueBlogImg/master/计算机网络/UDP首部.jpg)

UDP首部有8个字节，由4个字段构成，每个字段都是两个字节，

**源端口**： 源端口号，需要对方回信时选用，不需要时全部置0.

**目的端口**：目的端口号，在终点交付报文的时候需要用到。

**长度**：UDP的数据报的长度（包括首部和数据）其最小值为8（只有首部）

**校验和**：检测UDP数据报在传输中是否有错，有错则丢弃。

该字段是可选的，当源主机不想计算校验和，则直接令该字段全为0.

当传输层从IP层收到UDP数据报时，就根据首部中的目的端口，把UDP数据报通过相应的端口，上交给应用进程。

如果接收方UDP发现收到的报文中的目的端口号不正确（不存在对应端口号的应用进程0,），就丢弃该报文，并由ICMP发送“端口不可达”差错报文给对方。

### 1.2UDP校验
在计算校验和的时候，需要在UDP数据报之前增加12字节的伪首部，伪首部并不是UDP真正的首部。只是在计算校验和，临时添加在UDP数据报的前面，得到一个临时的UDP数据报。校验和就是按照这个临时的UDP数据报计算的。伪首部既不向下传送也不向上递交，而仅仅是为了计算校验和。这样的校验和，既检查了UDP数据报，又对IP数据报的源IP地址和目的IP地址进行了检验。

UDP伪首部结构和TCP伪首部相同。只不过UDP伪首部中协议字段值为17，而TCP为6.

UDP校验和的计算方法和IP数据报首部校验和的计算方法相似，都使用二进制反码运算求和再取反，但不同的是：IP数据报的校验和之检验IP数据报和首部，但UDP的校验和是把首部和数据部分一起校验。

发送方，首先是把全零放入校验和字段并且添加伪首部，然后把UDP数据报看成是由许多16位的子串连接起来，若UDP数据报的数据部分不是偶数个字节，则要在数据部分末尾增加一个全零字节（此字节不发送），接下来就按照二进制反码计算出这些16位字的和。将此和的二进制反码写入校验和字段。在接收方，把收到得UDP数据报加上伪首部（如果不为偶数个字节，还需要补上全零字节）后，按二进制反码计算出这些16位字的和。当无差错时其结果全为1。否则就表明有差错出现，接收方应该丢弃这个UDP数据报。

![](https://raw.githubusercontent.com/Hewie8023/VueBlogImg/master/计算机网络/UDP校验.png)

1. 校验时，若UDP数据报部分的长度不是偶数个字节，则需要填入一个全0字节，但是次字节和伪首部一样，是不发送的。
2. 如果UDP校验和校验出UDP数据报是错误的，可以丢弃，也可以交付上层，但是要附上错误报告，告诉上层这是错误的数据报。
3. 通过伪首部，不仅可以检查源端口号，目的端口号和UDP用户数据报的数据部分，还可以检查IP数据报的源IP地址和目的地址。

### 1.3UDP的复用和分用
当运输层从IP层收到UDP数据报时，就根据首部中的目的端口，把UDP数据报通过相应的端口，上交到最后的终点——应用进程。下图是UDP基于端口分用的示意图。
![](https://raw.githubusercontent.com/Hewie8023/VueBlogImg/master/计算机网络/UDP分用.png)

基于端口的复用示意图与上图相似，只是数据报的传输方向相反。
![](https://raw.githubusercontent.com/Hewie8023/VueBlogImg/master/计算机网络/UDP复用.png)



### 1.4UDP可靠性传输的实现
从应用层角度考虑：
- 提供超时重传，能避免数据报丢失。
- 提供确认序列号，可以对数据报进行确认和排序。

**本端**：首先在UDP数据报定义一个首部，首部包含确认序列号和时间戳，时间戳是用来计算RTT(数据报传输的往返时间)，从何计算出合适的RTO(重传的超时时间)。然后以等-停的方式发送数据报，即收到对端的确认之后才发送下一个的数据报。当时间超时，本端重传数据报，同时RTO扩大为原来的两倍，重新开始计时。

**对端**：接受到一个数据报之后取下该数据报首部的时间戳和确认序列号，并添加本端的确认数据报首部之后发送给对端。根据此序列号对已收到的数据报进行排序并丢弃重复的数据报。

**发送方的处理**：
1. 包发送确认后，由于还没有收到确认，先缓存
2. 收到确认包后，从缓存中删除发送的包
3. 接收方将丢失的包通知过来，或者超过一定的时候，若还没有收到确认的包，进行重传（注意，这个由接收线程触发）

**接收方的处理**：
1. 接收到包的数据，先将数据放到缓存中，a. 若有丢包现象，通知发送方，同时记录丢失的包 b.若是重传的包，从丢失的列表中删除
2.  发送确认包
3. 丢失的包，超时会让发送方再次发送

**一些情况分析**：

情况1：发送包a，接收方确认a，发送方收到确认：正常

情况2：发送包a，接收方确认a，发送方没有收到确认：发送方会重发此包，接收方收到此包忽略

情况3：发送包a，接收方没有收到a：发送方重发此包

情况4：发送包a，一直收不到确认，超过一定次数或时间后，结束

情况4：发送包a失败，结束

### 1.5UDP为什么乱序
tcp 协议头有 seq 和 ack_seq 用来保证 tcp包的时序, 如果出现缺少其中一块, 会进行重传, 而 udp没有seq 和 ack_seq 来保证, 所以会乱序

## 2、TCP
TCP是一个**面向连接的**(connection-oriented)、**可靠的**(reliable)、**字节流式**(byte stream)传输协议。

**面向连接**：在应用TCP协议进行通信之前双方通常需要通过**三次握手**来建立TCP连接，连接建立后才能进行正常的数据传输，因此广播和多播不会承载在TCP协议上。(谷歌提交了一个RFC文档，建议在TCP三次握手的过程允许SYN数据包中带数据，即 TFO(TCP Fast Open)，目前ubuntu14.04已经支持该TFO功能)。但是同时面向连接的特性给TCP带来了复杂的连接管理以及用于检测连接状态的存活检测机制。

**可靠性**：由于TCP处于多跳通信的IP层之上，而IP层并不提供可靠的传输，因此在TCP层看来就有四种常见传输错误问题，分别是比特错误(packet bit errors)、包乱序(packet reordering)、包重复(packet duplication)、丢包(packet erasure或称为packet drops)，TCP要提供可靠的传输，就需要有额外的机制处理这几种错误。因此个人理解可靠性体现在三个方面，首先TCP通过**超时重传和快速重传**两个常见手段来保证数据包的正确传输，也就是说接收端在没有收到数据包或者收到错误的数据包的时候会触发发送端的数据包重传(处理比特错误和丢包)。其次TCP接收端会缓存接收到的乱序到达数据，重排序后在向应用层提供有序的数据(处理包乱序)。最后TCP发送端会维持一个发送"窗口"动态的调整发送速率以适用接收端缓存限制和网络拥塞情况，避免了网络拥塞或者接收端缓存满而大量丢包的问题(降低丢包率)。因此**可靠性需要TCP协议具有超时与重传管理、窗口管理、流量控制、拥塞控制**等功能。另外TFO下TCP有可能向应用层提供重复的数据，也就是不可靠传输，但是只会发生在连接建立阶段，我们后续会进行介绍。

**字节流式**：应用层发送的数据会在TCP的发送端缓存起来，统一分片(例如一个应用层的数据包分成两个TCP包)或者打包(例如两个或者多个应用层的数据包打包成一个TCP数据包)发送，到接收端的时候接收端也是直接按照字节流将数据传递给应用层。作为对比，同样是传输层的协议，UDP并不会对应用层的数据包进行打包和分片的操作，一般一个应用层的数据包就对应一个UDP包。这个也是伴随TCP窗口管理、拥塞控制等。

### 2.1TCP首部格式
![](https://raw.githubusercontent.com/Hewie8023/VueBlogImg/master/计算机网络/TCP.png)

**源端口和目的端口**：各占2个字节，分别写入源端口和目的端口。

**序号seq**：占4字节。序号范围是【0，2^32 - 1】，共2^32（即4294967296）个序号。序号增加到2^32-1后，下一个序号就又回到0。也就是说，序号使用mod 2^32运算。TCP是面向字节流的。在一个TCP连接中传送的字节流中的每一个字节都按顺序编号。整个要传送的字节流的起始序号必须在连接建立时设置。首部中的序号字段值则是指的是本报文段所发送的数据的第一个字节的序号。例如，一报文段的序号是301，而接待的数据共有100字节。这就表明：本报文段的数据的第一个字节的序号是301，最后一个字节的序号是400。显然，下一个报文段（如果还有的话）的数据序号应当从401开始，即下一个报文段的序号字段值应为401。这个字段的序号也叫“报文段序号”。

**确认号ack**：占4字节，是期望收到对方下一个报文段的第一个数据字节的序号。例如，B正确收到了A发送过来的一个报文段，其序号字段值是501，而数据长度是200字节（序号501~700），这表明B正确收到了A发送的到序号700为止的数据。因此，B期望收到A的下一个数据序号是701，于是B在发送给A的确认报文段中把确认号置为701。注意，现在确认号不是501，也不是700，而是701。
总之：若确认号为= N，则表明：到序号N-1为止的所有数据都已正确收到。

**数据偏移**：占4位，它指出TCP报文段的数据起始处距离TCP报文段的起始处有多远。这个字段实际上是指出TCP报文段的首部长度。由于首部中还有长度不确定的选项字段，因此数据偏移字段是必要的，但应注意，“数据偏移”的单位是32位字（即以4字节的字为计算单位）。由于4位二进制数能表示的最大十进制数字是15，因此数据偏移的最大值是60字节，这也是TCP首部的最大字节（即选项长度不能超过40字节）。

**保留**：占6位，保留为今后使用，但目前应置为0 。

**下面有6个控制位，用来说明本报文段的性质**
**紧急URG**（URGent）：当URG=1时，表明紧急指针字段有效。它告诉系统此报文段中有紧急数据，应尽快发送（相当于高优先级的数据），而不要按原来的排队顺序来传送。例如，已经发送了很长的一个程序要在远地的主机上运行。但后来发现了一些问题，需要取消该程序的运行，因此用户从键盘发出中断命令。如果不使用紧急数据，那么这两个字符将存储在接收TCP的缓存末尾。只有在所有的数据被处理完毕后这两个字符才被交付接收方的应用进程。这样做就浪费了很多时间。

当URG置为1时，发送应用进程就告诉发送方的TCP有紧急数据要传送。于是发送方TCP就把紧急数据插入到本报文段数据的最前面，而在紧急数据后面的数据仍然是普通数据。这时要与首部中紧急指针（Urgent Pointer）字段配合使用。
应用场景：强制关闭时可使用

**确认ACK**（ACKnowledgment）：仅当ACK = 1时确认号字段才有效，当ACK = 0时确认号无效。TCP规定，在连接建立后所有的传送的报文段都必须把ACK置为1。

**推送 PSH**（PuSH）：当两个应用进程进行交互式的通信时，有时在一端的应用进程希望在键入一个命令后立即就能收到对方的响应。在这种情况下，TCP就可以使用推送（push）操作。这时，发送方TCP把PSH置为1，并立即创建一个报文段发送出去。接收方TCP收到PSH=1的报文段，就尽快地（即“推送”向前）交付接收应用进程。而不用再等到整个缓存都填满了后再向上交付。

**复位RST**（ReSeT）：当RST=1时，表名TCP连接中出现了严重错误（如由于主机崩溃或其他原因），必须释放连接，然后再重新建立传输连接。RST置为1还用来拒绝一个非法的报文段或拒绝打开一个连接。
应用场景：端口未打开、请求超时、提前关闭

**同步SYN**（SYNchronization）：在连接建立时用来同步序号。当SYN=1而ACK=0时，表明这是一个连接请求报文段。对方若同意建立连接，则应在响应的报文段中使SYN=1和ACK=1，因此SYN置为1就表示这是一个连接请求或连接接受报文。

**终止FIN**（FINis，意思是“完”“终”）：用来释放一个连接。当FIN=1时，表明此报文段的发送发的数据已发送完毕，并要求释放运输连接。

**窗口**：占2字节。窗口值是【0，2^16-1】之间的整数。窗口指的是发送本报文段的一方的接受窗口（而不是自己的发送窗口）。窗口值告诉对方：从本报文段首部中的确认号算起，接收方目前允许对方发送的数据量（以字节为单位）。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。总之，窗口值作为接收方让发送方设置其发送窗口的依据。

例如，发送了一个报文段，其确认号是701，窗口字段是1000.这就是告诉对方：“从701算起，我（即发送方报文段的一方）的接收缓存空间还可接受1000个字节数据（字节序号是701~1700），你在给我发数据时，必须考虑到这一点。”
总之：窗口字段明确指出了现在允许对方发送的数据量。窗口值经常在动态变化。

**检验和**：占2字节。检验和字段检验的范围包括首部和数据这两部分。和UDP用户数据报一样，在计算检验和时，要在TCP报文段的前面加上12字节的伪首部。伪首部的格式和UDP用户数据报的伪首部一样。但应把伪首部第4个字段中的17改为6（TCP的协议号是6）；把第5字段中的UDP中的长度改为TCP长度。接收方收到此报文段后，仍要加上这个伪首部来计算检验和。若使用TPv6,则相应的伪首部也要改变。

**紧急指针**：占2字节。紧急指针仅在URG=1时才有意义，它指出本报文段中的紧急数据的字节数（紧急数据结束后就是普通数据） 。因此，在紧急指针指出了紧急数据的末尾在报文段中的位置。当所有紧急数据都处理完时，TCP就告诉应用程序恢复到正常操作。值得注意的是，即使窗口为0时也可以发送紧急数据。

**选项**：长度可变，最长可达4字节。当没有使用“选项”时，TCP的首部长度是20字节。

TCP最初只规定了一种选项，即**最大报文段长度MSS**（Maximum Segment Szie）。注意MSS这个名词含义。MSS是每一个TCP报文段中的数据字段的最大长度。数据字段加上TCP首部才等于整个的TCP报文段。所以MSS并不是整个TCP报文段的最大长度，而是“TCP报文段长度减去TCP首部长度”

**为什么要规定一个最大报文长度MSS呢**?这并不是考虑接受方的接收缓存可能存放不下TCP报文段中的数据。实际上，MSS与接收窗口值没有关系。我们知道，TCP报文段的数据部分，至少要加上40字节的首部（TCP首部20字节和IP首部20字节，这里还没有考虑首部中的可选部分）才能组装成一个IP数据报。若选择较小的MSS长度，网络的利用率就降低。设想在极端情况下，当TCP报文段只含有1字节的数据时，在IP层传输的数据报的开销至少有40字节（包括TCP报文段的首部和IP数据报的首部）。这样，对网络的利用率就不会超过1/41。到了数据链路层还要加上一些开销。但反过来，若TCP报文段非常长，那么在IP层传输时就有可能要分解成多个短数据报片。在终点要把收到的各个短数据报片组成成原来的TCP报文段，当传输出错时还要进行重传，这些也都会使开销增大。

因此，MSS应尽可能大些，只要在IP层传输时不需要分片就行。由于IP数据报所经历的路径是动态变化的，因此在这条路径上确定的不需要的分片的MSS，如果改走另一条路径就可能需要进行分片。因此最佳的MSS是很难确定的。在连接过程中，双方都把自己能够支持的MSS写入这一字段，以后就按照这个数值传输数据，两个传送方向可以有不同的MSS值。若主机未填写这一项，则MSS的默认值是536字节长。因此，所有在互联网上的主机都应该接受的报文段长度是536+20（固定首部长度）=556字节。

**窗口扩大选项**是为了扩大窗口。我们知道，TCP首部中窗口字段长度是16位，因此最大的窗口大小为64K字节。虽然这对早期的网络是足够用的，但对于包含卫星信道的网络，传播时延和宽带都很大，要获得高吞吐量需要更大的窗口大小。

窗口扩大选项占3字节，其中有一个字节表示移位值S。新的窗口值等于TCP首部中的窗口位数从16增大到（16+S）。移位值允许使用的最大值是14，相当于窗口最大值增大到2^（16+14）-1=2^30-1。

窗口扩大选项可以在双方初始建立TCP连接时进行协商。如果连接的某一端实现了窗口扩大，当它不再需要扩大其窗口时，可发送S=0选项，使窗口大小回到16。

**时间戳选项**占10字节，其中最主要的字段是时间戳字段（4字节）和时间戳回送回答字段（4字节）。时间戳选项有以下两个概念：
- 用来计算往返时间RTT。发送方在发送报文段时把当前时钟的时间值放入时间戳字段，接收方在确认该报文段时把时间戳字段复制到时间戳回送回答字段。因此，发送方在收到确认报文后，可以准确地计算出RTT来。
- 用于处理TCP序号超过2^32的情况，这又称为防止序号绕回PAWS。我们知道，TCP报文段的序号只有32位，而每增加2^32个序号就会重复使用原来用过的序号。当使用高速网络时，在一次TCP连接的数据传送中序号很可能被重复使用。例如，当使用1.5Mbit/s的速度发送报文段时，序号重复要6小时以上。但若用2.5Gbit/s的速率发送报文段，则不到14秒钟序号就会重复。为了使接收方能够把新的报文段和迟到很久的报文段区分开，则可以在报文段中加上这种时间戳。

### 2.2TCP三次握手

![](https://raw.githubusercontent.com/Hewie8023/VueBlogImg/master/计算机网络/TCP三次握手.png)

假设 A 为客户端，B 为服务器端。
- 首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。
- A 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个初始的序号 x。
- B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。
- A 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。
- B 收到 A 的确认后，连接建立。

注：
1. TCP规定，SYN报文段（SYN=1的报文段）不能携带数据，但需要消耗掉一个序号。
2. TCP规定，ACK报文段可以携带数据，但是如果不携带数据则不消耗序号。
3. TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。

#### 2.2.1三次握手的原因
第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。

客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。

### 2.3TCP四次挥手
![](https://raw.githubusercontent.com/Hewie8023/VueBlogImg/master/计算机网络/TCP四次挥手.png)

假设 A 为客户端，B 为服务器端。
- A 发送连接释放报文，FIN=1，seq = u，此时A进入FIN-WAIT-1状态。
- B 收到之后发出确认，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时B就进入了CLOSE-WAIT状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时 TCP 属于**半关闭状态**，B 能向 A 发送数据但是 A 不能向 B 发送数据。
- A收到B的确认请求之后，A进入了FIN-WAIT-2状态，并等待B发送释放连接报文。
- 当 B 不再需要连接时，发送连接释放报文，FIN=1，ack=u+1，由于在半连接状态，B可能又发送了一些数据，假定此时序列号为seq=w。此时B就进入了LAST-ACK状态，等待A的确认。
- A 收到后发出确认，ACK=1，ack=w+1，seq=u+1，此时A进入 TIME-WAIT 状态，等待 2 MSL（最大报文存活时间）后释放连接。
- B 收到 A 的确认后释放连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。

#### 2.3.1四次挥手的原因
建立连接的时候， 服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。

而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送，从而导致多了一次。

#### 2.3.2TIME_WAIT
MSL（Maximum Segment Lifetime），**最长报文段寿命**，TCP允许不同的实现可以设置不同的MSL值。
- 第一，保证客户端发送的最后一个ACK报文能够到达服务器，因为这个ACK报文可能丢失，站在服务器的角度看来，我已经发送了FIN+ACK报文请求断开了，客户端还没有给我回应，应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。
- 第二，防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。客户端发送完最后一个确认报文后，在这个2MSL时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文。

#### 2.3.3如果已经建立了连接，但是客户端突然出现故障了怎么办？
TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。

#### 2.3.4UDP和TCP校验的时候为什么要加入伪首部？
伪首部并非TCP&UDP数据报中实际的有效成分。伪首部是一个虚拟的数据结构，其中的信息是从数据报所在IP分组头的分组头中提取的，既不向下传送也不向上递交，而仅仅是为计算校验和。这样的校验和，既校验了TCP&UDP用户数据的源端口号和目的端口号以及TCP&UDP用户数据报的数据部分，又检验了IP数据报的源IP地址和目的地址。伪报头保证TCP&UDP数据单元到达正确的目的地址。因此，伪报头中包含IP地址并且作为计算校验和需要考虑的一部分。最终目的端根据伪报头和数据单元计算校验和以验证通信数据在传输过程中没有改变而且到达了正确的目的地址。

**为什么伪首部要有目的IP地址**
学习过通信系统原理后，我们知道数据传输过程中会产生误码，0可能变为1，1可能变为0，并且每种校验码都有一定的查错能力，超过这个范围，就无法察觉错误了，而早期的通信环境大概比较糟糕，因此，在传输过程中出现误码，可能使IP报文的目的地址出现错误，接收主机的UDP计算校验和时，目的IP地址来自IP层，由于目的IP地址出现错误，导致发送主机计算检验和时使用的目的IP地址与接收主机计算检验和时使用的目的IP地址不同，UDP发现错误，丢弃报文

**为什么伪首部要有源IP地址**
为了让接收主机确认源IP地址没有出现错误。
假设我们想要开发一款基于UDP的程序，A发送UDP报文给B，B要发送回应报文给A，假设传输过程出现误码，源IP地址出现错误，则A计算检验和时使用的源IP地址与B计算校验和时使用的源IP地址不同，B就可以发现错误，从而丢弃报文，定时重传等可靠性由应用程序自己保证

**为什么伪首部要有协议字段**
为了确认操作系统交付给UDP的报文是UDP报文

**为什么伪首部要有UDP的长度**
可能是为了防止UDP头部的长度字段出现错误，导致解析UDP报文时出现差错

#### 2.3.5TCP同时打开和同时关闭
##### 2.3.5.1同时打开
两个应用程序同时彼此执行主动打开的情况是可能的，尽管发生的可能性极小。每一方必须发送一个SYN，且这些SYN必须传递给对方。这需要每一方使用一个对方熟知的端口最为本地端口。

当出现同时打开的情况时，状态迁移图就与标准的连接状态迁移图不一样了。两端几乎同时发送SYN并进入SYN_SENT状态。当每一端收到SYN时，状态变为SYN_RCVD，同时它们都再发SYN并对收到的SYN进行确认。当双方都接收到SYN及相应的ACK时，状态都变为了ESTABLISHED。

一个同时打开的连接需要交换需要交换4个报文段，比正常的三次握手多一个。没有任何一端称为客户或服务器，因为每一端既是客户又是服务器。

![](https://raw.githubusercontent.com/Hewie8023/VueBlogImg/master/计算机网络/同时打开.jpg)

##### 2.3.5.2同时关闭
在标准的情况下通过一方发送FIN来关闭连接，但是双方都执行主动关闭也是有可能的，TCP协议也允许这样的同时关闭。当应用层发出关闭命令时，两方均从ESTABLISHED变为FIN_WAITE_1。这将导致双发各发送一个FIN，两个FIN经过网络传输后分别达到另一端。收到FIN后，状态由FIN_WAIT_1变签到CLOSING，并将发送最后的ACK。当收到最后的ACK时，状态变化为TIME_WAIT。

![](https://raw.githubusercontent.com/Hewie8023/VueBlogImg/master/计算机网络/同时关闭.jpg)

### 2.4TCP可靠性传输
1. 确认应答机制：每个ACK都有对应的确认序列号，意思是告诉发送者已经收到了数据，下一个数据应该从哪里开始发送。 
2. 超时重传机制：两种情况
    1）如果主机A发送给主机B的报文，主机B在规定的时间内没有及时收到主机A发送的报文，我们可以认为是ACK丢了，这时就需要触发超时重传机制。
    2）如果主机A未收到B发来的确认应答，也可能是因为ACK丢了。因此主机B会收到很多重复的数据，那么，TCP协议需要能够识别出那些包是重复的包，并且把重复的包丢弃，这时候我们可以用前面提到的序列号，很容易做到去重的效果 
3. 流量控制
4. 拥塞控制
5. 校验和
6. 连接管理机制（三次握手，四次挥手）

### 2.5TCP流量控制：滑动窗口机制

流量控制（用滑动窗口实现）就是让发送方的发送速率不要太快，要让接收方来得及接收。

TCP连接发送方发送一个数据报，对端会进行确认在发送下一个数据包。

滑动窗口协议**允许发送方在停止并等待确认前发送多个数据分组**。由于发送方不必每发一个分组（IP数据包或TCP报文段）就停下来等待确认，因此该协议可以加速数据的传输，增大了吞吐量。

停止等待协议是最简单但也是最基础的数据链路层协议。与滑动窗口协议不同的是停止等待协议就是每发送完一个分组就停止发送，等待对方的确认，在收到确认后再发送下一个分组。当发送窗口和接收窗口的大小都等于**1**时，就是停止等待协议。

TCP的可靠数据传输服务确保进程从接收缓冲区中读出的数据流是正确地，有序的，不重复的，即读出的字节流与连接的另一方系统发送的字节流是完全一样的，但是实际上接收方应用进程不一定时刻都在读数据，那么如果应用进程读取数据相当慢，而发送方发送的数据太多、太快，就很容易使接收方的接收缓冲区溢出。所以**TCP采用大小可变的滑动窗口给应用程序提供流量控制服务**，用以消除接收缓冲区溢出的可能。实际上TCP报文段头部的16位窗口字段写入的数值就是接收方当前给对方设置的发送窗口的上限，发送窗口在连接建立时由双方商定，但是在通信过程中，接收方根据自己的接收缓冲区资源大小随时动态的调整对方发送窗口的上限（滑动窗口即可以滑动滴）。

举个例子：TCP通信是全双工的，这里为了方便理解，就以一个方向为例，假设A为发送方，B为接收方。A会有一个发送窗口，B有一个接收窗口。在连接建立的时候B告诉A其接收窗口是400字节，因此发送方的发送窗口不能超过接收方给的接收窗口大小。（假设一个报文段100字节，报文段序号初始值为1.图中大写ACK表示头部中的确认位ACK，小写ack表示确认字段的值）

![](https://raw.githubusercontent.com/Hewie8023/VueBlogImg/master/计算机网络/流量控制01.png)

为了便于大家看，我们采用另一种方式描述发送窗口，假设A现在收到B的确认报文段，窗口是20字节，确认号是31（表示B期望收到的下一个序号是31，而序号30为止的数据已经收到了），根据此条件，A构造出自己的发送窗口，如下图：

![](https://raw.githubusercontent.com/Hewie8023/VueBlogImg/master/计算机网络/流量控制02.png)

**发送窗口表示在没有收到B确认的情况下，A也可以连续把发送窗口的数据发送出去**。但是已经发送过的数据在未收到确认之前，它还需要暂时保留，以便于超时重传时使用。发送窗口越大，它就可以在收到对方确认之前发送更多的数据，因而获得更高的传输效率。（但是接收方要来得及处理之前的数据）

发送窗口的位置由窗口前沿和后沿的位置共同确定。
它后沿变化有两种，（1）不动（没有收到新的确定）（2）前移（收到新的确认）；

前沿是不断向前移动的，但也可能不动
1. 不动（没有收到新确认，对方窗口也不变）
2. 不动（收到新的确认，对方的应用层没有读取数据，接收窗口缩小了，使前沿正好不变，后沿前移窗口就变小了）

假定A发送了序号为31～41的数据。这时，发送窗口的位置并未改变，发送窗口内靠后的11个字节（黑色部分）表示 已发送但未收到确认。
![](https://raw.githubusercontent.com/Hewie8023/VueBlogImg/master/计算机网络/流量控制03.png)

即小于P1的是已发送并收到确认的序号，而大于P3的是不允许发送的部分。

P3-P1=A的发送窗口

P2-P1=已发送但是未接收到确认的字节数

P3-P2=允许发送但是未发送的字节数（可用窗口或有效窗口）

再看B的接收窗口大小是20，在接收窗口外面到30号位置的数据是接收并确认的，因此可以丢弃。在接收窗口中，B收到了32和33的数据（白色的是没有接收到的），但它们不是按序到达的，因为并没有收到31号数据。B只能对按序达收到的数据中的最高序号给出确认，因此B发送的确认报文字段的确认号依然是31号（确认号就是告诉发送方期望下一次收到数据包的序号）。

现在假定B收到了序号为31的数据，并把31～33的数据交付主机，然后B删除这些数据。接着把窗口向前移动3个序号，如下图，同时给a发送确认，其中的窗口值仍为20，但确认号变为34。表明B已经收到序号33为止的数据。

![](https://raw.githubusercontent.com/Hewie8023/VueBlogImg/master/计算机网络/流量控制04.png)

当A发送完窗口内的所有数据后，未收到任何确认时，窗口内就没有可发送的数据。经过一段时间后（超时计时器），若仍未收到确认，A将会重新发送。

此外发送方和接收方都有自己的缓冲区

**发送缓冲区存放**：
1. 发送发TCP准备发送的数据
2. TCP已发送但尚未收到确认的数据（为超时重传准备）

**接收缓冲区存放**：
1. 按序到达但未被应用程序读取的数据
2. 未按序到达的数据

实际上发送窗口大小不仅仅是由接收端决定的，其还受网络的拥塞程度决定。发送窗口=MIN{接收窗口，拥塞窗口}

#### 2.5.1滑动窗口丢包原理
**发送端丢包原理**
![](https://raw.githubusercontent.com/Hewie8023/VueBlogImg/master/计算机网络/发送端丢包原理-发送端.png)

当某一段报文丢失了，图中（1001-2000）数据段丢失了，接收方没有接收到该数据段，则会一直给发送端发送ACK（下一个是1001），如果发送端连续收到同样的ACK（下一个是1001），就会将对应的（1001-2000）重新发送，这时候如果接收端收到1001后，再次返回的就是ACK（7001）。这种机制被称为“高速重发机制”（快速重传）

**接收端丢包原理**
![](https://raw.githubusercontent.com/Hewie8023/VueBlogImg/master/计算机网络/发送端丢包原理-接收端.png)

接收端的下一个2001丢失了，但是发送端收到了ACK（下一个3001），说明1-3000的数据段已经接收到了，数据已经传输到了发送端，所以不需要理会。

### 2.6TCP拥塞控制
如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收方能来得及接收（端到端的问题），而拥塞控制是为了降低整个网络的拥塞程度。

TCP 主要通过四个算法来进行拥塞控制：慢开始、拥塞避免、快重传、快恢复。

拥塞的标志
1. 重传计时器超时 
2. 接收到三个重复确认

#### 2.6.1慢开始
算法原理：当主机开始发送数据时，如果立即将大量数据字节注入到网络，那么就有可能因为不清楚当前网络的负荷情况而引起网络阻塞。所以，最好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。通常在刚刚发送报文段时，先把**拥塞窗口cwnd**设置为一个最大报文段MSS的数值（虽然 TCP 的窗口基于字节，但是这里设窗口的大小单位为报文段）。而在每收到一个新的报文段的确认后，把拥塞窗口增加至多一个MSS的数值。用这样的方法逐步增大发送方的拥塞窗口cwnd，可以使分组注入到网络的速率更加合理。（慢开始当中的“慢”并不是指cwnd的增长速率慢，而是在TCP开始发送报文段时先设置cwnd = 1,使得发送方在开始时只发送一一个报文段）

当rwnd足够大的时候，为了防止拥塞窗口cwnd的增长引起网络阻塞，还需要另外一个变量------**慢开始门限ssthresh**.
- 当cwnd < ssthresh时，使用上述慢启动算法；
- 当cwnd >ssthresh时，停止使用慢启动算法，改用拥塞避免算法；

**慢开始的局限性**
- 需要获得网络内部流量分布的信息，浪费可用的网络容量，额外开销；
- 估算合理的ssthresh值并不容易，可能耗时较长；

#### 2.6.2拥塞避免（按线性规律增长）
拥塞避免并非完全能够避免拥塞，是说在拥塞避免阶段将拥塞窗口控制为按线性规律增长，使网络比较不容易出现拥塞。

思路：让拥塞窗口cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞控制窗口加一。

无论是在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认，虽然没有收到确认可能是其他原因的分组丢失，但是因为无法判定，所以都当做拥塞来处理），就把慢开始门限设置为出现拥塞时的发送窗口大小的一半（ssthresh=cwnd/2）。然后把拥塞窗口设置为1，执行慢开始算法。

![](https://raw.githubusercontent.com/Hewie8023/VueBlogImg/master/计算机网络/慢开始和拥塞避免.png)

**加法增大与乘法减小**
**乘法减小**：无论是慢开始阶段还是拥塞避免，只要出现了网络拥塞（超时），就把慢开始门限值ssthresh减半 
**加法增大**：执行拥塞避免算法后，拥塞窗口线性缓慢增大，防止网络过早出现拥塞

#### 2.6.3快重传
快重传要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。

![](https://raw.githubusercontent.com/Hewie8023/VueBlogImg/master/计算机网络/快重传.png)

由于不需要等待设置的重传计时器到期，能尽早重传未被确认的报文段，能提高整个网络的吞吐量。

#### 2.6.4快恢复（与快重传配合）
1. 采用快恢复算法时，慢开始只在TCP连接建立时和网络出现超时时才使用。 
2. 当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半。但是接下去并不执行慢开始算法。 
3. 考虑到如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将cwnd设置为ssthresh的大小，然后执行拥塞避免算法。

![](https://raw.githubusercontent.com/Hewie8023/VueBlogImg/master/计算机网络/快恢复.png)

### 2.7TCP四种计时器
#### 2.7.1重传计时器
在滑动窗口协议中，接受窗口会在连续收到的包序列中的最后一个包向接收端发送一个ACK，当网络拥堵的时候，发送端的数据包和接收端的ACK包都有可能丢失。TCP为了保证数据可靠传输，就规定在重传的“时间片”到了以后，如果还没有收到对方的ACK，就重发此包，以避免陷入无限等待中。

当TCP发送报文段时，就创建该特定报文的重传计时器。可能发生两种情况：
1. 若在计时器截止时间到之前收到了对此特定报文段的确认，则撤销此计时器。
2. 若在收到了对此特定报文段的确认之前计时器截止时间到，则重传此报文段，并将计时器复位。

#### 2.7.2持久计时器
先来考虑一下情景：发送端向接收端发送数据包知道接受窗口填满了，然后接受窗口告诉发送方接受窗口填满了停止发送数据。此时的状态称为“零窗口”状态，发送端和接收端窗口大小均为0.直到接受TCP发送确认并宣布一个非零的窗口大小。但这个确认会丢失。我们知道TCP中，对确认是不需要发送确认的。若确认丢失了，接受TCP并不知道，而是会认为他已经完成了任务，并等待着发送TCP接着会发送更多的报文段。但发送TCP由于没有收到确认，就等待对方发送确认来通知窗口大小。双方的TCP都在永远的等待着对方。

要打开这种死锁，TCP为每一个链接使用一个持久计时器。当发送TCP收到窗口大小为0的确认时，就坚持启动计时器。当坚持计时器期限到时，发送TCP就发送一个特殊的报文段，叫做**探测报文**。这个报文段只有一个字节的数据。他有一个序号，但他的序号永远不需要确认；甚至在计算机对其他部分的数据的确认时该序号也被忽略。探测报文段提醒接受TCP：确认已丢失，必须重传。

坚持计时器的值设置为重传时间的数值。但是，若没有收到从接收端来的响应，则需发送另一个探测报文段，并将坚持计时器的值加倍和复位。发送端继续发送探测报文段，将坚持计时器设定的值加倍和复位，直到这个值增大到门限值（通常是60秒）为止。在这以后，发送端每个60秒就发送一个探测报文，直到窗口重新打开。

#### 2.7.3保活计时器
保活计时器使用在某些实现中，用来防止在两个TCP之间的连接出现长时间的空闲。假定客户打开了到服务器的连接，传送了一些数据，然后就保持静默了。也许这个客户出故障了。在这种情况下，这个连接将永远的处理打开状态。

要解决这种问题，在大多数的实现中都是使服务器设置保活计时器。每当服务器收到客户的信息，就将计时器复位。通常设置为两小时。若服务器过了两小时还没有收到客户的信息，他就发送探测报文段。若发送了10个探测报文段（每一个间隔75秒）还没有响应，就假定客户除了故障，因而就终止了该连接。

这种连接的断开当然不会使用四次握手，而是直接硬性的中断和客户端的TCP连接。

#### 2.7.4时间等待计时器
时间等待计时器是在四次握手的时候使用的。四次握手的简单过程是这样的：假设客户端准备中断连接，首先向服务器端发送一个FIN的请求关闭包（FIN=final），然后由established过渡到FIN-WAIT1状态。服务器收到FIN包以后会发送一个ACK，然后自己有established进入CLOSE-WAIT.此时通信进入半双工状态，即留给服务器一个机会将剩余数据传递给客户端，传递完后服务器发送一个FIN+ACK的包，表示我已经发送完数据可以断开连接了，就这便进入LAST_ACK阶段。客户端收到以后，发送一个ACK表示收到并同意请求，接着由FIN-WAIT2进入TIME-WAIT阶段。服务器收到ACK，结束连接。此时（即客户端发送完ACK包之后），客户端还要等待2MSL（MSL=maxinum segment lifetime最长报文生存时间，2MSL就是两倍的MSL）才能真正的关闭连接。

### 2.8time_wait如何避免
首先服务器可以设置SO_REUSEADDR套接字选项来通知内核，如果端口忙，但TCP连接位于TIME_WAIT状态时可以重用端口。在一个非常有用的场景就是，如果你的服务器程序停止后想立即重启，而新的套接字依旧希望使用同一端口，此时SO_REUSEADDR选项就可以避免TIME_WAIT状态。

### 2.9三次握手的隐患
SYN- Flood攻击是当前网络上最为常见的DDoS攻击，也是最为经典的拒绝服务攻击，它就是利用了TCP协议实现上的一个缺陷，通过向网络服务所在端口发送大量 的伪造源地址的攻击报文，就可能造成目标服务器中的半开连接队列被占满，从而阻止其他合法用户进行访问。

**原理**：攻击者首先伪造地址对服务器发起SYN请求，服务器回应(SYN+ACK)包，而真实的IP会认为，我没有发送请求，不作回应。服务 器没有收到回应，这样的话，服务器不知 道(SYN+ACK)是否发送成功，默认情况下会重试5次（tcp_syn_retries）。这样的话，对于服务器的内存，带宽都有很大的消耗。攻击者如果处于公网，可以伪造IP的话，对于服务器就很难根据IP来判断攻击者，给防护带来很大的困难。

**SYN Flood 防护措施**
1. 无效连接监视释放
这种方法不停的监视系统中半开连接和不活动连接，当达到一定阈值时拆除这些连接，释放系统资源。这种绝对公平的方法往往也会将正常的连接的请求也会被释放掉，”伤敌一千，自损八百“

2. 延缓TCB分配方法
SYN Flood关键是利用了，SYN数据报文一到，系统立即分配TCB资源，从而占用了系统资源，因此有俩种技术来解决这一问题

**Syn Cache技术**
这种技术在收到SYN时不急着去分配TCB，而是先回应一个ACK报文，并在一个专用的HASH表中（Cache）中保存这种半开连接，直到收到正确的ACK报文再去分配TCB

**Syn Cookie技术**
Syn Cookie技术则完全不使用任何存储资源，它使用一种特殊的算法生成Sequence Number，这种算法考虑到了对方的IP、端口、己方IP、端口的固定信息，以及对方无法知道而己方比较固定的一些信息，如MSS、时间等，在收到对方 的ACK报文后，重新计算一遍，看其是否与对方回应报文中的（Sequence Number-1）相同，从而决定是否分配TCB资源。

### 2.10既然有了拥塞控制,为什么还会有拥塞比如游戏卡顿
路由器只是把溢出的流量丢弃处理，其他的什么都不做。

源主机发现丢包了，就会将流量降速差不多一半，这就是流量拥塞控制。

但是，是先发生“路由器流量溢出（丢包）”，然后才触发了“源主机的流量拥塞控制”。

源主机的流量拥塞控制（Congestion Control）机制，永远都无法避免路由节点的网络拥塞，从而造成的流量溢出（丢包）！

### 2.11close_wait作用，如果close_wait不关闭有什么问题？
在被动关闭连接情况下，在已经接收到FIN，但是还没有发送自己的FIN的时刻，连接处于CLOSE_WAIT状态。通常来讲，CLOSE_WAIT状态的持续时间应该很短，正如SYN_RCVD状态。

如果一直保持在CLOSE_WAIT状态，那么只有一种情况就是在对方关闭连接之后服务器程序自己没有进一步发出ack信号。换句话说，就是在对方连接关闭之后，程序里没有检测到，或者程序压根就忘记了这个时候需要关闭连接，于是这个资源就一直被程序占着。

**出现大量close_wait的现象**，主要原因是某种情况下对方关闭了socket链接，但是我方忙与读或者写，没有关闭连接。代码需要判断socket，一旦读到0，断开连接，read返回负，检查一下errno，如果不是AGAIN，就断开连接。

一直存在导致端口一直被占用。

### 2.12TCP粘包、拆包
粘包问题主要还是因为接收方不知道消息之间的界限，不知道一次性提取多少字节的数据所造成的。

发送方引起的粘包是由TCP协议本身造成的，TCP为提高传输效率，发送方往往要收集到足够多的数据后才发送一个TCP段。若连续几次需要send的数据都很少，通常TCP会根据negal优化算法把这些数据合成一个TCP段后一次发送出去，这样接收方就收到了粘包数据。

两种粘包情况：
1. 发送端需要等缓冲区满才发送出去，造成粘包（发送数据时间间隔很短，数据了很小，会合到一起，产生粘包）
2. 接收方不及时接收缓冲区的包，造成多个包接收（客户端发送了一段数据，服务端只收了一小部分，服务端下次再收的时候还是从缓冲区拿上次遗留的数据，产生粘包） 

两种拆包情况：
1. 要发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包。
2. 待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包。

**粘包、拆包解决办法**
通过以上分析，我们清楚了粘包或拆包发生的原因，那么如何解决这个问题呢？解决问题的关键在于如何给每个数据包添加边界信息，常用的方法有如下几个：

1、发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。

2、发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。

3、可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。

### 2.13UDP会不会粘包
TCP为了保证可靠传输并减少额外的开销（每次发包都~~~~要验证），采用了基于流的传输，基于流的传输不认为消息是一条一条的，是无保护消息边界的（保护消息边界：指传输协议把数据当做一条独立的消息在网上传输，接收端一次只能接受一条独立的消息）。

UDP则是面向消息传输的，是有保护消息边界的，接收方一次只接受一条独立的信息，所以不存在粘包问题。

举个例子：有三个数据包，大小分别为2k、4k、6k，如果采用UDP发送的话，不管接受方的接收缓存有多大，我们必须要进行至少三次以上的发送才能把数据包发送完，但是使用TCP协议发送的话，我们只需要接受方的接收缓存有12k的大小，就可以一次把这3个数据包全部发送完毕。






